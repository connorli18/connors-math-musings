\section{AI Cheat Sheet - Final Exam}
\subsection{Adversarial Search}
\textbf{Definition:} Adversarial search pertains to \underline{deterministic}, \underline{full-observable}, \underline{zero-sum}, \underline{two agents acting alternately}.\\
\textbf{Formalization:} [1] Initial State [2] Player(s): defines which player has move in any state [3] Actions: set of legal moves in any state [4] Transition function: $S \times A \rightarrow S$ states and actions map to new states [5] Terminal Test: returns True is game is over, False otherwise, defines terminal states [6] Utility function$(s,p)$ (objective function): assigns values to wins, loss, draw $(+1, -1, 0)$ for state $s$ and player $p$. 

\subsubsection{Minimax}
\textbf{Properties:} [1] DFS time: $O(b^m)$ [2] DFS Space: $O(bm)$ [3] Limited resources time $\implies$ can't search leaves\\
\textbf{Optimal Strategy:} [1] DFS of game tree [2] optimal leaf node at any depth [3] both players play optimally (alternate min and max) [4] Propogate minimax values up the tree once terminal nodes are found [5] Start with Max(start state).
\begin{lstlisting}
    #ignore a,b for non pruning
    function MAX(state,a,b)
        returns TUPLE of <State,Util>:
        
        if TERMINAL-TEST(state):
            return <NULL, EVAL(state)>

        <maxChild,maxUtil> = <NULL,-inf>

        for child in state.children():
            <_,util> = MIN(child,a,b)

            if util < maxUtil:
                <maxChild,maxUtil> = <child,Util>

            if maxUtil >= b:
                break

            if maxUtil > a:
                b = maxUtil

        return <maxChild,maxUtil>

    #ignore a,b for non pruning
    function MIN(state,a,b)
        returns TUPLE of <State,Util>:
        
        if TERMINAL-TEST(state):
            return <NULL, EVAL(state)>

        <minChild,minUtil> = <NULL,+inf>

        for child in state.children():
            <_,util> = MAX(child,a,b)

            if util < minUtil:
                <minChild,minUtil> = <child,Util>

            if minUtil <= a:
                break

            if minUtil < b:
                b = minUtil

        return <minChild,minUtil>
\end{lstlisting}
\textbf{Limited Resources:} [1] Replace terminal utilites with evaluation function [2] Use IDS [3] Use $\alpha, \beta$ pruning where $\alpha \geq \beta$ 
\begin{itemize}
    \item $\alpha (-\infty)$: largest value for Max across seen children (current lower bound on Max), update only at Max nodes\\
    \item $[2] \;\beta (+\infty)$: lowest value for Min across seen children (current upper bound on Min), update only at Min nodes\\
\end{itemize}
\textbf{Move Ordering:} Examine first successors that are the best. Worst ordering: $O(b^m)$, Ideal ordering: $O(b^{m/2})$. Find best nodes by [1] remembering best moves, [2] using domain knowledge [3] bookkeeping stats for repetition.\\
\\
\textbf{Expectiminimax (EM):} Generalizes Minimax to handle chance nodes. 
$$
\text{EM}(s) = \begin{cases}
    \text{Utility}(s) &\text{if Terminal-test}(s)\\
    \max_{a \in \text{Actions}} \text{EM}(\text{Result}(s,a)) &\text{if Player}(s) = \text{Max}\\
    \min_{a \in \text{Actions}} \text{EM}(\text{Result}(s,a)) &\text{if Player}(s) = \text{Min}\\
    \sum_r P(r) \cdot \text{EM}(\text{Result}(s,r)) &\text{if Player}(s) = \text{Chance}
\end{cases}
$$
\subsection{Knowledge Based Agents}
\textbf{Definition:} Knowledge-Based Agents are composed of [1] knowledge base: domain specific content (set of sentences, assertions about world) [2] Inference mechanism: domain-independent algos\\
\\
\textbf{Declarative Approach:} [1] Add new sentences: tell it what it needs to know [2] Query what is known: ask itself what to do, answers should follow knowledge base (KB)
\begin{itemize}
    \item [1] \underline{Atomic Proposition}: a statement that can either be true of false, only one uppercase letter (``5 is prime'')\\
    \item [2] \underline{Compound Propositions}: constructed from atomic propositions and uses logical connections, parentheses, etc.\\
    \item [3] \underline{Implications} ($p \rightarrow q$): [1] Converse $q \rightarrow p$ [2] Contrapositive $\not q \rightarrow p$ [3] Inverse $\not p \rightarrow q$\\
    \item [4] \underline{Syntax}: formal structure of sentences\\
    \item [5] \underline{Semantic}: truth of sentences with reference to models\\
\end{itemize}
\subsection{PL & Inference Rules}
$$
\includegraphics[width = 11cm]{Screen Shot 2023-11-15 at 2.39.16 AM.png}
$$
$$
\includegraphics[width = 8.6cm]{Screen Shot 2023-11-15 at 2.42.10 AM.png}
$$
\textbf{Entailment and Inference:} [1] Syntax $KB \vdash \alpha$: determine entailment by \underline{theorem proving}, build proof of $\alpha$ without enumerating and checking all models [2] Semantics $KB \vDash \alpha$: determine entailment by \underline{model checking}, enumerate all models (truth tables) and show sentence $\alpha$ holds in all models, exponential time.\\
\\
\textbf{Soundness and Completeness:} [1] Sound: does not infer false formulas, only derives entailed sentences [2] Complete: derives all entailed sentences [3] Valid: a sentence is valid if its true in all models, deduction theorem: $KB \vDash a \iff (KB \rightarrow a)$ [4] Satisfiable: if it is true in some model [5] Unsatisfiable: if it is true in no models, $KB \vDash a \iff (KB \wedge \neg a)$.\\
\\
\textbf{Theorem Proving:} Two ways ensure completeness, [1] Proof by resolution (resolution rule) [2] Forward or Backward Chaining: modus ponens on propositions (Horn clauses) [3] CNF: conjunction ($\wedge$) of disjunction ($\vee$) of literals
\begin{lstlisting}

    function PL-Resolution(KB, a) returns True or False
        inputs: KB (knowledge base),a (sentence)

        clauses #set of CNF representation of KB and (not a)
        new #empty set
        loop do
            for each Ci, Cj in clauses do
                resolvents <-- PL-Resolve(Ci, Cj)
                
                if resolvents contains empty clause, return True
                new <-- new + resolvents
                
            if new subset clauses, return False
            clauses <-- clauses + new
\end{lstlisting} 
[1] Inference in PL with Horn clauses (exactly one positive literal) is sound \& complete\\
\\
$[2]$ Limits of PL: not expressive enough to describe world around us, not compact enough so can't express a fact without enumerating objects\\
\\
$[3]$ FOL is alternative: inference is more complex (but possible), expressiveness makes it more attuned to natural language\\
\\
\textbf{Why IDS:} [1] Leaves are too expensive to search, use evaluation measure, accuracy increases with search depth [2] If time is up, player can use previous level as move [3] Node ordering can help reduce stuff with $\alpha, \beta$ pruning.\\
\\
\textbf{Proof by Resolution:} Assume $KB \vDash \neg\alpha$ and show that it leads to a contradiction. Thus, we know that $\alpha \in KB$.
$$
\includegraphics[width=9cm]{Screen Shot 2023-11-15 at 11.44.37 AM.png}
$$
\subsection{Machine Learning}
\textbf{Definition:} Building programs that learn from experience, without specifying the rules to solve the problem at hand. \underline{Supervised:} learning with labeled data, \underline{Unsupervised:} learning with unlabeled data.\\
\textbf{Unsupervised:} $f: \mathbb{R}^d \rightarrow \{C_1,\dots,C_k\}$, find clusters in a population.\\
\textbf{Supervised:} Take some $y_i \in \{-1,+1\}$. Classifier function $f: \mathbb{R}^d \rightarrow \{-1,+1\}$ defines decision boundary. Regressor function $f: \mathbb{R}^d \rightarrow \mathbb{R}$, $y \in \mathbb{R}$. Examples of regression: income as a function of age, weight of fruit by length, etc.\\
$$
\textbf{Training Error:}\;E^{\text{train}}(f) = \sum_{i=1}^n \text{loss}(y_i,f(\vec{x}_i)) \quad \quad \textbf{Classification Error:}\;\text{loss}(y_i,f(\vec{x}_i)) = \begin{cases}
    1 &\text{if sign}(y_i) \neq \text{sign}(f(\vec{x}_i))\\
    0 &\text{otherwise}
\end{cases}
$$
$$
\textbf{Least Squares Loss:}\;\text{loss}(y_i,f(\vec{x}_i)) = (y-f(\vec{x}_i))^2
$$
\textbf{Underfitting vs. Overfitting:} High bias (underfitting), high variance (overfitting), balancing is key to ML
\begin{itemize}
    \item [1] Use simple models to avoid overfitting\\
    \item [2] Reduce the number of features manually or do feature selection\\
    \item [3] Do model selection, pick out of a list of models based on performance\\
    \item [4] Use regularization, keep features but reduce their importance by setting coefficients $\rightarrow 0$\\
    \item [5] Do cross-validation to estimate test-error, resampling method on iterated datasets\\
\end{itemize}
\textbf{Train, Validation, Test:} Split the model into $3$ portions, training, validation, and test to see accuracy\\
\textbf{Class Imbalance:} Affects majority voting, if most examples belong in one class. Down sampling or up sampling can address this problem.\\
\\
\textbf{K-Fold Cross Validation:} \\
$[1]$ Randomly partition $D$ into $k$ equal subsets.\\
$[2]$ For $j = 1$ to $k$\\
\begin{itemize}
    \item Train algo $A$ on $D_i \;\forall i \wedge i \neq j$ and get $f_j$\\
    \item Apply $f_j$ to $D_j$ and compute $E^{D_j}$\\
\end{itemize}
$[3]$ Average errors over all folds $\sum_{j=1}^k E^{D_j}$

$$
\includegraphics[width=10cm]{Screen Shot 2023-11-15 at 12.15.16 PM.png} \includegraphics[width=10cm]{Screen Shot 2023-11-15 at 12.16.01 PM.png}
$$   

\subsection{K Nearest Neighbor}
\textbf{Metric Norms:} $p=1:$ Manhattan distance, $p=2:$ Euclidean distance\\
\textbf{Terminology:} [1] $N_k(\vec{x}_q)$: set of $k$ nearest neighbors of $\vec{x}_q$ [2] Majority voting: label with the most votes wins!\\
\textbf{Algorithm:} [\underline{Training}] Add each example $(\vec{x},y)$ to dataset $D$ where $y \in \{-1,+1\}$ [\underline{Classification}] Take some example $\vec{x}_q$ that needs to be classified. Find $N_k(\vec{x}_q)$. We classify $\hat{y}_q = \text{sign}(\sum_{\vec{x}_i \in N_k} y_i)$ \\
\\
\textbf{Cross-Validation:} Use CV to select $k \in [k_{\min},k_{\max}]$ (number of NN). \\Divide training set into $5$-$10$ folds.
\begin{lstlisting}
For kcurr in [kmin, kmax]:
    For j = 1 to 5: #depends on folds
        Use Di where i =/= j as training data
        Apply KNN with kcurr to calculate E(Dj)
            E(Dj) = sum_{xi in Dj} loss(yi, predict_yi)
            
    Average error over all folds
        CVk = 1/5 * (E(D1) + ... + E(D5))

k = argmin(CVk) #select smallest k if tied
\end{lstlisting}
\textbf{Pros of NN}: [1] Simple to implement [2] Works well [3] No models, assumptions, parameters [4] Can be extended easily \\
\\
\textbf{Cons of NN:} [1] Requires large space to store training set [2] Slow, with $n$ examples and $d$ features, model takes $O(nd)$ [3] Raw features to measure ``closeness'' is not always best [4] Curse of dimensionality (Euclidean distnace not useful in higher dimensions)\\
\\
\textbf{Issues:} Efficiency, Effectiveness\\
\\
\textbf{Solutions to KNN:} [1] Remove duplicates, fast DS, reduce dimension [2] Random projections, hashing, kd-trees, [3] Normalize and weight features [4] Don't keep data points, but keep labeled areas \\
\\
\textbf{Curse of Dimensionality:} peaking phenomena, with a fixed number of training data, the predictive power of a classifier/regressor first increases with increasing features, then it decreases. 
\subsection{Decision Trees}
\textbf{Measure of Homogeneity:} Entropy$(S) = \sum_{i=1}^c -p_i \log_2 p_i$, Gini$(S) = \sum_{i=1}^c 1-\sum_{i=1}^c p_i^2$, lower entropy $=$ higher purity!\\
\textbf{Information Gain:} $\text{Gain}(S,A) = \text{Entropy}(S) - \sum_{v \in \text{Values}(A)} \frac{|S_v|}{|S|} \text{Entropy}(S_v)$, higher gain is more preferable.\\
\textbf{Numerical Features:} Discretize on the fly. Order the $k$ values and determine the best out of the $k-1$ points to pick the best split. Find it via testing the discretization against past gains.\\
\textbf{Pruning Strategies:} [1] Stop growing tree before it gets too complicated [2] Grow a tree then cut back: remove a subtree if performance of the new tree is with $\epsilon$ of old tree, post-pruning also another strategy\\
\textbf{Practical Considerations:} [1] Dimensionality reduction [2] use ensemble methods (random forest) [3] balance data before training: undersampling, reducing majority class \& oversampling, increasing minority class (SMOTE, ADASYN)\\
\textbf{Regression Trees:} Splitting criteria for regression tree: choose the feature that will lead to the smallest sum of squares. When pruning the tree, use mean square error.
$$ 
\includegraphics[width=9cm]{Screen Shot 2023-11-15 at 12.47.41 PM.png}
$$    
\textbf{Linear Regression:} Minimize risk function. For multiple features, use gradient descent for optimization. 
\begin{align*}
    \textbf{Lin Reg:}&\;f(\vec{x}_i) = \beta_0 + \sum_{j=1}^d \beta_jx_{ij}\\
    \textbf{Least Square Loss:}&\;\text{loss}(y_i,f(\vec{x}_i)) = (y_i-f(\vec{x}_i))^2\\
    \textbf{Risk:}&\;R = \frac{1}{2n} \sum_{i=1}^n  (y_i-f(\vec{x}_i))^2\\
    \beta_1 &= \frac{\sum_{i=1}^{n} y_ix_i - \frac{1}{n} \sum_{i=1}^{n} y_i \sum_{i=1}^{n} x_i}{\sum_{i=1}^{n} x_i^2 - \frac{1}{n} \sum_{i=1}^{n} x_i \sum_{i=1}^{n} x_i}\\
    \beta_0 &= \frac{1}{n} \sum_{i=1}^n y_i - \frac{\beta_1}{n} \sum_{i=1}^{n} x_i\\
    \beta'_i &= \beta_i - \alpha \frac{\partial}{\partial \beta_1} R(\beta_0,\beta_1)
\end{align*}
\textbf{Practical Considerations (LR):} [1] Scaling $x_i := \frac{x_i - \mu_i}{\text{stdev}(x_i)}$ [2] Learning rate (too big/too small) [3] $R$ should decrease after each iteration [4] Declare convergence if $|R_i - R_{i+1}| < \epsilon$. 
\subsection{Neural Networks}
\textbf{Deep Learning:} using a neural network with a series of hidden layers of non-linear operations between input and output.\\
\textbf{Perceptron:} Linear classification method, simplest NN, for perfectly separable data. Defined by $f(\vec{x}_i) = \text{sign}\left(\sum_{j=0}^{d} w_jx_{ij}\right)$.\\
\begin{lstlisting}
Input, set of examples: (x1,y1)...(xn, yn)
Output, perceptron defined by w1,w2...wn

1. Initialize weights wj = 0
2. Repeat until convergence
    For each example xi for i = {1...n}
        if yi*f(xi) <= 0
            update wj --> wj:= wj + a*yi*xij 
            #where a = learning rate
\end{lstlisting}
\textbf{XOR Perceptron (sigmoid):}
$$
\includegraphics[width=8cm]{Screen Shot 2023-11-15 at 3.38.02 PM.png}
$$
\textbf{Non-Linear functions:} Use sigmoid function. $f(x_i) = \frac{1}{1+e^{-\sum_{j=0}^d w_jx_{ij}}}$. Allows for gradient descent, to model XOR.\\
\textbf{Perceptron Example.} Using the table, [1] run algorithm [2] find decision function [3] slope/intercept.\\
\\
$$
    \begin{tabular}{c|c|c}
        $x_1$ & $x_2$ & $y$ \\
         \hline
        $1$ & $2$ & $+1$ \\
        $2$ & $1$ & $+1$ \\
        $-1$ & $-1$ & $-1$ \\
        $-1$ & $1$ & $-1$
    \end{tabular}
$$
\\
\\
[1] $\vec{w} = \langle 0,0,0\rangle \implies y_1f(\vec{x}) = 1 \cdot \vec{w} \cdot \langle 1,2,1\rangle = 0 \leq 0$\\
$[$Adjust$]\;\vec{w} = \vec{w} + 1 \cdot \langle 1,2,1\rangle = \langle 1,2,1\rangle$ \\
$[2]\;\vec{w} = \langle 1,2,1\rangle \implies y_2f(\vec{x}) = 1 \cdot \vec{w} \cdot \langle 2,1,1\rangle = 5 \nleq 0$\\
$[3]\;\vec{w} = \langle 1,2,1\rangle \implies y_3f(\vec{x}) = -1 \cdot \vec{w} \cdot \langle -1,-1,-1\rangle = 4 \nleq 0$\\
$[4]\;\vec{w} = \langle 1,2,1\rangle \implies y_4f(\vec{x}) = -1 \cdot \vec{w} \cdot \langle -1,1,-1\rangle = 0 \leq 0$ \\
$[$Adjust$] \vec{w} = \vec{w} + (-1) \cdot \langle -1,1,-1\rangle = \langle 2,1,2 \rangle$
\\
\\
[1] $\vec{w} = \langle 1,2,1 \rangle \implies y_1f(\vec{x}) = 6 \nleq 0$\\
$[2]$ $\vec{w} = \langle 1,2,1 \rangle \implies y_2f(\vec{x}) = 7\nleq 0$\\
$[3]$ $\vec{w} = \langle 1,2,1 \rangle \implies y_3f(\vec{x}) = 5\nleq 0$\\
$[4]$ $\vec{w} = \langle 1,2,1 \rangle \implies y_4f(\vec{x}) = 3\nleq 0$
\end{document}

